"use strict";(self.webpackChunkq_01_docs=self.webpackChunkq_01_docs||[]).push([[2688],{2024:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>u,frontMatter:()=>i,metadata:()=>c,toc:()=>l});var t=s(7624),r=s(2172);const i={title:"Outbox Subscribers",sidebar_label:"Outbox Subscribers",sidebar_position:4,description:"RabbitMQ event consumers and processing patterns"},a="Outbox Subscribers",c={id:"products/map.q01.io/core-api-platform-v4/advanced-topics/outbox-subscribers",title:"Outbox Subscribers",description:"RabbitMQ event consumers and processing patterns",source:"@site/docs/products/map.q01.io/core-api-platform-v4/06-advanced-topics/outbox-subscribers.md",sourceDirName:"products/map.q01.io/core-api-platform-v4/06-advanced-topics",slug:"/products/map.q01.io/core-api-platform-v4/advanced-topics/outbox-subscribers",permalink:"/docs/products/map.q01.io/core-api-platform-v4/advanced-topics/outbox-subscribers",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Outbox Subscribers",sidebar_label:"Outbox Subscribers",sidebar_position:4,description:"RabbitMQ event consumers and processing patterns"},sidebar:"mapSidebar",previous:{title:"Media Handling",permalink:"/docs/products/map.q01.io/core-api-platform-v4/advanced-topics/media-handling"},next:{title:"Caching Strategies",permalink:"/docs/products/map.q01.io/core-api-platform-v4/advanced-topics/caching-strategies"}},o={},l=[{value:"Overview",id:"overview",level:2},{value:"Event Flow",id:"event-flow",level:2},{value:"Subscriber Implementation",id:"subscriber-implementation",level:2},{value:"Node.js Subscriber",id:"nodejs-subscriber",level:3},{value:"Search Indexer Example",id:"search-indexer-example",level:3},{value:"Cache Invalidator Example",id:"cache-invalidator-example",level:3},{value:"Idempotency",id:"idempotency",level:2},{value:"Why Idempotency Matters",id:"why-idempotency-matters",level:3},{value:"Idempotency Strategies",id:"idempotency-strategies",level:3},{value:"Error Handling",id:"error-handling",level:2},{value:"Retry with Exponential Backoff",id:"retry-with-exponential-backoff",level:3},{value:"Dead Letter Queue Monitoring",id:"dead-letter-queue-monitoring",level:3},{value:"Scaling Subscribers",id:"scaling-subscribers",level:2},{value:"Multiple Instances",id:"multiple-instances",level:3},{value:"Consumer Acknowledgment",id:"consumer-acknowledgment",level:3},{value:"Monitoring and Metrics",id:"monitoring-and-metrics",level:2},{value:"Prometheus Metrics",id:"prometheus-metrics",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"\u2705 DO:",id:"-do",level:3},{value:"\u274c DON&#39;T:",id:"-dont",level:3},{value:"Summary",id:"summary",level:2},{value:"Related Concepts",id:"related-concepts",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.M)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"outbox-subscribers",children:"Outbox Subscribers"}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Outbox subscribers"})," are microservices that consume events from the RabbitMQ fanout exchange, enabling event-driven architecture and eventual consistency across the Q01 platform."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Common Subscribers:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"search-indexer"})," - Updates Elasticsearch indices"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"cache-invalidator"})," - Clears Redis cache"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"analytics-writer"})," - Writes to data warehouse"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"notification-sender"})," - Sends emails/push notifications"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"webhook-dispatcher"})," - Calls external webhooks"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"audit-logger"})," - Writes to audit log"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Benefits:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u2705 Decoupled microservices"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Asynchronous processing"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Scalable event processing"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 At-least-once delivery"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Independent failure handling"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"event-flow",children:"Event Flow"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Write Operation (POST/PUT/PATCH/DELETE)\n    \u2193\n1. Update TB_ANAG_{DIM}00\n2. Insert OUTBOX event\n3. COMMIT transaction\n    \u2193\nBackground Publisher (polls OUTBOX)\n    \u2193\nRabbitMQ Fanout Exchange (corewrite.fanout)\n    \u2193\nSubscribers (all receive same event):\n\u251c\u2500\u2500 search-indexer\n\u251c\u2500\u2500 cache-invalidator\n\u251c\u2500\u2500 analytics-writer\n\u251c\u2500\u2500 notification-sender\n\u2514\u2500\u2500 webhook-dispatcher\n"})}),"\n",(0,t.jsx)(n.h2,{id:"subscriber-implementation",children:"Subscriber Implementation"}),"\n",(0,t.jsx)(n.h3,{id:"nodejs-subscriber",children:"Node.js Subscriber"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"const amqp = require('amqplib');\n\nclass OutboxSubscriber {\n  constructor(queueName, exchangeName = 'corewrite.fanout') {\n    this.queueName = queueName;\n    this.exchangeName = exchangeName;\n    this.connection = null;\n    this.channel = null;\n  }\n\n  async connect() {\n    // Connect to RabbitMQ\n    this.connection = await amqp.connect(process.env.RABBITMQ_URL);\n    this.channel = await this.connection.createChannel();\n\n    // Assert exchange\n    await this.channel.assertExchange(this.exchangeName, 'fanout', {\n      durable: true\n    });\n\n    // Create queue\n    const queue = await this.channel.assertQueue(this.queueName, {\n      durable: true,\n      autoDelete: false\n    });\n\n    // Bind queue to exchange\n    await this.channel.bindQueue(queue.queue, this.exchangeName, '');\n\n    // Set prefetch (process one message at a time)\n    await this.channel.prefetch(1);\n\n    console.log(`[${this.queueName}] Waiting for events...`);\n  }\n\n  async subscribe(handler) {\n    await this.channel.consume(this.queueName, async (msg) => {\n      if (!msg) return;\n\n      try {\n        const event = JSON.parse(msg.content.toString());\n\n        console.log(`[${this.queueName}] Processing event:`, event.EVENT_TYPE);\n\n        // Handle event (idempotent)\n        await handler(event);\n\n        // Acknowledge message\n        this.channel.ack(msg);\n\n        console.log(`[${this.queueName}] Event processed successfully`);\n      } catch (error) {\n        console.error(`[${this.queueName}] Error processing event:`, error);\n\n        // Reject and requeue (will retry)\n        this.channel.nack(msg, false, true);\n      }\n    });\n  }\n\n  async close() {\n    await this.channel.close();\n    await this.connection.close();\n  }\n}\n\n// Usage\nconst subscriber = new OutboxSubscriber('search-indexer');\nawait subscriber.connect();\n\nawait subscriber.subscribe(async (event) => {\n  await handleSearchIndexEvent(event);\n});\n"})}),"\n",(0,t.jsx)(n.h3,{id:"search-indexer-example",children:"Search Indexer Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"const { Client } = require('@elastic/elasticsearch');\n\nclass SearchIndexer {\n  constructor() {\n    this.elasticsearch = new Client({\n      node: process.env.ELASTICSEARCH_URL\n    });\n  }\n\n  async handleEvent(event) {\n    const { EVENT_TYPE, AGGREGATE_TYPE, AGGREGATE_ID, PAYLOAD } = event;\n\n    // Check idempotency (already processed?)\n    if (await this.isProcessed(event.OUTBOX_ID)) {\n      console.log('Event already processed, skipping');\n      return;\n    }\n\n    switch (EVENT_TYPE) {\n      case 'ProductCreated':\n        await this.indexProduct(PAYLOAD);\n        break;\n\n      case 'ProductUpdated':\n        await this.updateProduct(AGGREGATE_ID, PAYLOAD);\n        break;\n\n      case 'ProductDeleted':\n        await this.deleteProduct(AGGREGATE_ID);\n        break;\n\n      default:\n        console.log(`Unknown event type: ${EVENT_TYPE}`);\n    }\n\n    // Mark as processed\n    await this.markProcessed(event.OUTBOX_ID);\n  }\n\n  async indexProduct(product) {\n    await this.elasticsearch.index({\n      index: 'products',\n      id: product.PRD_ID,\n      body: {\n        name: product.XPRD01,\n        price: product.XPRD02,\n        code: product.XPRD03,\n        category: product.XPRD05,\n        active: product.XPRD06,\n        created_at: product.CREATED_AT,\n        updated_at: product.UPDATED_AT\n      }\n    });\n\n    console.log(`Indexed product: ${product.PRD_ID}`);\n  }\n\n  async updateProduct(productId, updates) {\n    await this.elasticsearch.update({\n      index: 'products',\n      id: productId,\n      body: {\n        doc: {\n          name: updates.XPRD01,\n          price: updates.XPRD02,\n          updated_at: updates.UPDATED_AT\n        }\n      }\n    });\n\n    console.log(`Updated product: ${productId}`);\n  }\n\n  async deleteProduct(productId) {\n    await this.elasticsearch.delete({\n      index: 'products',\n      id: productId\n    });\n\n    console.log(`Deleted product: ${productId}`);\n  }\n\n  async isProcessed(outboxId) {\n    // Check Redis for processed events\n    const redis = require('redis').createClient();\n    const exists = await redis.exists(`processed:${outboxId}`);\n    return exists === 1;\n  }\n\n  async markProcessed(outboxId) {\n    // Store in Redis with 30-day TTL\n    const redis = require('redis').createClient();\n    await redis.set(`processed:${outboxId}`, '1', 'EX', 2592000);\n  }\n}\n\n// Start subscriber\nconst indexer = new SearchIndexer();\nconst subscriber = new OutboxSubscriber('search-indexer');\n\nawait subscriber.connect();\nawait subscriber.subscribe((event) => indexer.handleEvent(event));\n"})}),"\n",(0,t.jsx)(n.h3,{id:"cache-invalidator-example",children:"Cache Invalidator Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"const Redis = require('ioredis');\n\nclass CacheInvalidator {\n  constructor() {\n    this.redis = new Redis(process.env.REDIS_URL);\n  }\n\n  async handleEvent(event) {\n    const { EVENT_TYPE, AGGREGATE_TYPE, AGGREGATE_ID, PAYLOAD } = event;\n\n    const keys = this.getCacheKeys(AGGREGATE_TYPE, AGGREGATE_ID, PAYLOAD);\n\n    for (const key of keys) {\n      await this.redis.del(key);\n      console.log(`Invalidated cache: ${key}`);\n    }\n  }\n\n  getCacheKeys(dimension, recordId, payload) {\n    const keys = [];\n\n    // Invalidate specific record cache\n    keys.push(`${dimension}:${recordId}`);\n\n    // Invalidate list caches\n    keys.push(`${dimension}:list:*`);\n\n    // Dimension-specific invalidation\n    if (dimension === 'PRD' && payload.XPRD05) {\n      // Invalidate category cache\n      keys.push(`CAT:${payload.XPRD05}:products`);\n    }\n\n    if (dimension === 'ORD' && payload.XORD_CUSTOMER_ID) {\n      // Invalidate customer orders cache\n      keys.push(`CUST:${payload.XORD_CUSTOMER_ID}:orders`);\n    }\n\n    return keys;\n  }\n}\n\n// Start subscriber\nconst invalidator = new CacheInvalidator();\nconst subscriber = new OutboxSubscriber('cache-invalidator');\n\nawait subscriber.connect();\nawait subscriber.subscribe((event) => invalidator.handleEvent(event));\n"})}),"\n",(0,t.jsx)(n.h2,{id:"idempotency",children:"Idempotency"}),"\n",(0,t.jsx)(n.h3,{id:"why-idempotency-matters",children:"Why Idempotency Matters"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"At-least-once delivery"})," means events may be processed multiple times:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"RabbitMQ redelivery on subscriber crash"}),"\n",(0,t.jsx)(n.li,{children:"Network failures"}),"\n",(0,t.jsx)(n.li,{children:"Manual replay"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Idempotent processing ensures:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u2705 Same result regardless of repetition"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 No duplicate data"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Safe reprocessing"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"idempotency-strategies",children:"Idempotency Strategies"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1. Check if already processed:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"async function handleEvent(event) {\n  // Check if event already processed\n  if (await isProcessed(event.OUTBOX_ID)) {\n    console.log('Event already processed, skipping');\n    return;\n  }\n\n  // Process event\n  await processEvent(event);\n\n  // Mark as processed\n  await markProcessed(event.OUTBOX_ID);\n}\n\nasync function isProcessed(outboxId) {\n  const redis = new Redis();\n  return await redis.exists(`processed:${outboxId}`) === 1;\n}\n\nasync function markProcessed(outboxId) {\n  const redis = new Redis();\n  await redis.set(`processed:${outboxId}`, Date.now(), 'EX', 2592000); // 30 days\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"2. Use unique constraints:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"async function indexProduct(product) {\n  // Elasticsearch uses document ID as unique constraint\n  await elasticsearch.index({\n    index: 'products',\n    id: product.PRD_ID,  // Unique ID\n    body: product\n  });\n\n  // Multiple calls with same ID \u2192 same result (idempotent)\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"3. Check-and-set patterns:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"async function updateCounter(event) {\n  const key = `counter:${event.AGGREGATE_ID}`;\n\n  // Get current value\n  const current = await redis.get(key) || 0;\n\n  // Only increment if not already incremented for this event\n  if (current < event.PAYLOAD.counter_value) {\n    await redis.set(key, event.PAYLOAD.counter_value);\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,t.jsx)(n.h3,{id:"retry-with-exponential-backoff",children:"Retry with Exponential Backoff"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"class ResilientSubscriber extends OutboxSubscriber {\n  async subscribe(handler, maxRetries = 3) {\n    await this.channel.consume(this.queueName, async (msg) => {\n      if (!msg) return;\n\n      let retryCount = 0;\n      let success = false;\n\n      while (retryCount < maxRetries && !success) {\n        try {\n          const event = JSON.parse(msg.content.toString());\n\n          await handler(event);\n\n          this.channel.ack(msg);\n          success = true;\n        } catch (error) {\n          retryCount++;\n\n          console.error(\n            `[${this.queueName}] Error (attempt ${retryCount}/${maxRetries}):`,\n            error.message\n          );\n\n          if (retryCount >= maxRetries) {\n            // Max retries exceeded - move to dead letter queue\n            await this.sendToDeadLetterQueue(msg);\n            this.channel.ack(msg);\n          } else {\n            // Wait before retry (exponential backoff)\n            await this.sleep(Math.pow(2, retryCount) * 1000);\n          }\n        }\n      }\n    });\n  }\n\n  async sendToDeadLetterQueue(msg) {\n    const dlqExchange = 'corewrite.dlq';\n    const event = JSON.parse(msg.content.toString());\n\n    await this.channel.assertExchange(dlqExchange, 'direct', { durable: true });\n\n    await this.channel.publish(\n      dlqExchange,\n      this.queueName,\n      msg.content,\n      {\n        persistent: true,\n        headers: {\n          'x-original-queue': this.queueName,\n          'x-failed-at': new Date().toISOString(),\n          'x-error': 'Max retries exceeded'\n        }\n      }\n    );\n\n    console.log(`[${this.queueName}] Sent to DLQ:`, event.OUTBOX_ID);\n  }\n\n  sleep(ms) {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"dead-letter-queue-monitoring",children:"Dead Letter Queue Monitoring"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"class DeadLetterQueueMonitor {\n  constructor() {\n    this.subscriber = new OutboxSubscriber('corewrite.dlq');\n  }\n\n  async start() {\n    await this.subscriber.connect();\n\n    await this.subscriber.subscribe(async (event) => {\n      // Alert on DLQ messages\n      await this.sendAlert({\n        title: 'Event Processing Failed',\n        event_id: event.OUTBOX_ID,\n        event_type: event.EVENT_TYPE,\n        aggregate: `${event.AGGREGATE_TYPE}/${event.AGGREGATE_ID}`,\n        timestamp: new Date().toISOString()\n      });\n\n      // Log to monitoring system\n      console.error('[DLQ] Failed event:', event);\n    });\n  }\n\n  async sendAlert(data) {\n    // Send to Slack, email, PagerDuty, etc.\n    await fetch(process.env.SLACK_WEBHOOK_URL, {\n      method: 'POST',\n      body: JSON.stringify({\n        text: `\u26a0\ufe0f ${data.title}\\nEvent: ${data.event_type}\\nID: ${data.event_id}`\n      })\n    });\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"scaling-subscribers",children:"Scaling Subscribers"}),"\n",(0,t.jsx)(n.h3,{id:"multiple-instances",children:"Multiple Instances"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"# docker-compose.yml\nversion: '3'\nservices:\n  search-indexer-1:\n    image: search-indexer:latest\n    environment:\n      RABBITMQ_URL: amqp://rabbitmq:5672\n      ELASTICSEARCH_URL: http://elasticsearch:9200\n    restart: always\n\n  search-indexer-2:\n    image: search-indexer:latest\n    environment:\n      RABBITMQ_URL: amqp://rabbitmq:5672\n      ELASTICSEARCH_URL: http://elasticsearch:9200\n    restart: always\n\n  search-indexer-3:\n    image: search-indexer:latest\n    environment:\n      RABBITMQ_URL: amqp://rabbitmq:5672\n      ELASTICSEARCH_URL: http://elasticsearch:9200\n    restart: always\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Benefits:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u2705 Parallel processing (faster throughput)"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 High availability (if one crashes, others continue)"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Load balancing (RabbitMQ distributes messages)"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"consumer-acknowledgment",children:"Consumer Acknowledgment"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"// Acknowledge only after successful processing\nawait this.channel.consume(queueName, async (msg) => {\n  try {\n    await processEvent(msg);\n    this.channel.ack(msg);  // \u2705 Success\n  } catch (error) {\n    this.channel.nack(msg, false, true);  // \u274c Reject and requeue\n  }\n});\n"})}),"\n",(0,t.jsx)(n.h2,{id:"monitoring-and-metrics",children:"Monitoring and Metrics"}),"\n",(0,t.jsx)(n.h3,{id:"prometheus-metrics",children:"Prometheus Metrics"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"const promClient = require('prom-client');\n\n// Metrics\nconst eventsProcessed = new promClient.Counter({\n  name: 'events_processed_total',\n  help: 'Total events processed',\n  labelNames: ['event_type', 'status']\n});\n\nconst processingDuration = new promClient.Histogram({\n  name: 'event_processing_duration_seconds',\n  help: 'Event processing duration',\n  labelNames: ['event_type']\n});\n\n// Track metrics\nasync function handleEvent(event) {\n  const timer = processingDuration.startTimer({ event_type: event.EVENT_TYPE });\n\n  try {\n    await processEvent(event);\n\n    eventsProcessed.inc({ event_type: event.EVENT_TYPE, status: 'success' });\n    timer();\n  } catch (error) {\n    eventsProcessed.inc({ event_type: event.EVENT_TYPE, status: 'error' });\n    timer();\n    throw error;\n  }\n}\n\n// Expose metrics endpoint\nconst express = require('express');\nconst app = express();\n\napp.get('/metrics', async (req, res) => {\n  res.set('Content-Type', promClient.register.contentType);\n  res.end(await promClient.register.metrics());\n});\n\napp.listen(9090);\n"})}),"\n",(0,t.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsx)(n.h3,{id:"-do",children:"\u2705 DO:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Implement idempotency:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"// \u2705 Good - check if already processed\nif (await isProcessed(event.OUTBOX_ID)) {\n  return;\n}\nawait process(event);\nawait markProcessed(event.OUTBOX_ID);\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Handle errors gracefully:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"// \u2705 Good - retry with backoff\ntry {\n  await process(event);\n} catch (error) {\n  if (retryCount < maxRetries) {\n    await sleep(Math.pow(2, retryCount) * 1000);\n    return retry();\n  } else {\n    await sendToDLQ(event);\n  }\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Monitor subscriber health:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"// \u2705 Good - expose health endpoint\napp.get('/health', (req, res) => {\n  res.json({ status: 'healthy', queue: queueName });\n});\n"})}),"\n",(0,t.jsx)(n.h3,{id:"-dont",children:"\u274c DON'T:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Don't assume exactly-once delivery:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"// \u274c Bad - not idempotent\nawait redis.incr(`counter:${event.AGGREGATE_ID}`);\n\n// \u2705 Good - idempotent\nawait redis.set(`counter:${event.AGGREGATE_ID}`, event.PAYLOAD.count);\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Don't block on external calls:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"// \u274c Bad - synchronous external call\nawait externalAPI.notify(event);  // Blocks queue\n\n// \u2705 Good - async with timeout\nPromise.race([\n  externalAPI.notify(event),\n  timeout(5000)\n]).catch(error => log(error));\n"})}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u2705 Subscribers consume events from RabbitMQ fanout exchange"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Common patterns: search indexing, cache invalidation, notifications"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Idempotency required (at-least-once delivery)"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Error handling with retry and dead letter queue"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Scale with multiple subscriber instances"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Monitor with Prometheus metrics"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Key Takeaways:"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Implement idempotent event handlers"}),"\n",(0,t.jsx)(n.li,{children:"Use retry with exponential backoff"}),"\n",(0,t.jsx)(n.li,{children:"Move failed events to dead letter queue"}),"\n",(0,t.jsx)(n.li,{children:"Scale horizontally with multiple instances"}),"\n",(0,t.jsx)(n.li,{children:"Monitor processing metrics"}),"\n",(0,t.jsx)(n.li,{children:"Acknowledge only after successful processing"}),"\n",(0,t.jsx)(n.li,{children:"Handle failures gracefully"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"related-concepts",children:"Related Concepts"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/docs/products/map.q01.io/core-api-platform-v4/write-patterns/outbox-pattern",children:"Outbox Pattern"})," - Event sourcing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/docs/products/map.q01.io/core-api-platform-v4/advanced-topics",children:"Advanced Topics"})," - Overview"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/docs/products/map.q01.io/core-api-platform-v4/advanced-topics/webhook-integration",children:"Webhook Integration"})," - External notifications"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.M)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},2172:(e,n,s)=>{s.d(n,{I:()=>c,M:()=>a});var t=s(1504);const r={},i=t.createContext(r);function a(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);